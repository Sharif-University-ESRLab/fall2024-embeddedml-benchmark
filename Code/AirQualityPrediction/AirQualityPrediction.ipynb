{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bf891d",
   "metadata": {},
   "source": [
    "# Air Quality Prediction for Embedded Systems\n",
    "\n",
    "This notebook demonstrates the process of building, quantizing, and evaluating lightweight machine learning models for air quality prediction, suitable for deployment on embedded systems. We use a popular public dataset, design two compact models, convert them to TensorFlow Lite, and compare their performance and size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd7d41c",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "We use the [UCI Air Quality Dataset](https://archive.ics.uci.edu/ml/datasets/Air+Quality) which contains sensor data for air quality prediction. The dataset is publicly available and widely used for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the UCI Air Quality dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip'\n",
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(BytesIO(r.content))\n",
    "df = pd.read_csv(z.open('AirQualityUCI.csv'), sep=';', decimal=',')\n",
    "\n",
    "df = df.iloc[:, :-2]\n",
    "df = df.dropna()\n",
    "\n",
    "for col in df.columns[2:]:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c6ee6",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "We select relevant features and the target variable (\"C6H6(GT)\" - Benzene concentration). Data is split into train and test sets, and normalized for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cfb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select features and target\n",
    "features = [\n",
    "    'CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'PT08.S2(NMHC)',\n",
    "    'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)',\n",
    "    'PT08.S5(O3)', 'T', 'RH', 'AH'\n",
    "]\n",
    "target = 'C6H6(GT)'\n",
    "\n",
    "X = df[features].values\n",
    "y = df[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe46ca0e",
   "metadata": {},
   "source": [
    "## 3. Model Design\n",
    "\n",
    "We design two compact neural network models suitable for embedded deployment:\n",
    "- **Model 1:** A small fully connected (Dense) neural network\n",
    "- **Model 2:** A small 1D Convolutional Neural Network (CNN)\n",
    "\n",
    "Both models are designed to have a small number of parameters (target: <60KB after quantization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Model 1: Small Dense NN\n",
    "def build_dense_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Model 2: Small 1D CNN\n",
    "def build_cnn_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Reshape((input_shape[0], 1), input_shape=input_shape),\n",
    "        layers.Conv1D(8, 3, activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "dense_model = build_dense_model((X_train.shape[1],))\n",
    "cnn_model = build_cnn_model((X_train.shape[1],))\n",
    "\n",
    "dense_model.summary()\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4672cf",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "We train both models using mean squared error loss and early stopping to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b131fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
    "\n",
    "dense_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "cnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history_dense = dense_model.fit(\n",
    "    X_train, y_train, validation_split=0.1, epochs=50, batch_size=32, callbacks=callbacks, verbose=2\n",
    ")\n",
    "history_cnn = cnn_model.fit(\n",
    "    X_train, y_train, validation_split=0.1, epochs=50, batch_size=32, callbacks=callbacks, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d066c",
   "metadata": {},
   "source": [
    "## 5. Model Conversion to TensorFlow Lite\n",
    "\n",
    "We convert both models to TensorFlow Lite format with post-training quantization to minimize size for embedded deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('Models', exist_ok=True)\n",
    "\n",
    "def convert_to_tflite(model, model_name, quantize=True):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    if quantize:\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        def representative_dataset():\n",
    "            for i in range(100):\n",
    "                yield [X_train[i:i+1].astype(np.float32)]\n",
    "        converter.representative_dataset = representative_dataset\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.int8\n",
    "        converter.inference_output_type = tf.int8\n",
    "    tflite_model = converter.convert()\n",
    "    with open(f'Models/{model_name}.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    return tflite_model\n",
    "\n",
    "dense_model.save('Models/dense_model.h5')\n",
    "cnn_model.save('Models/cnn_model.h5')\n",
    "\n",
    "tflite_dense = convert_to_tflite(dense_model, 'dense_model_quant')\n",
    "tflite_cnn = convert_to_tflite(cnn_model, 'cnn_model_quant')\n",
    "\n",
    "def get_file_size(path):\n",
    "    return os.path.getsize(path) / 1024  # KB\n",
    "\n",
    "sizes = {\n",
    "    'Dense Original': get_file_size('Models/dense_model.h5'),\n",
    "    'Dense TFLite': get_file_size('Models/dense_model_quant.tflite'),\n",
    "    'CNN Original': get_file_size('Models/cnn_model.h5'),\n",
    "    'CNN TFLite': get_file_size('Models/cnn_model_quant.tflite'),\n",
    "}\n",
    "sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994ba93",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "We evaluate both the original and quantized models on the test set and compare their accuracy and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_eval = dense_model.evaluate(X_test, y_test, verbose=0)\n",
    "cnn_eval = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Dense Model - Test MAE: {dense_eval[1]:.3f}\")\n",
    "print(f\"CNN Model   - Test MAE: {cnn_eval[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tflite_model(tflite_path, X_test, y_test):\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    y_preds = []\n",
    "    for i in range(len(X_test)):\n",
    "        x = X_test[i:i+1].astype(np.float32)\n",
    "        scale, zero_point = input_details[0]['quantization']\n",
    "        x_q = (x / scale + zero_point).astype(np.int8)\n",
    "        interpreter.set_tensor(input_details[0]['index'], x_q)\n",
    "        interpreter.invoke()\n",
    "        y_q = interpreter.get_tensor(output_details[0]['index'])\n",
    "        y_pred = (y_q.astype(np.float32) - output_details[0]['quantization'][1]) * output_details[0]['quantization'][0]\n",
    "        y_preds.append(y_pred[0][0])\n",
    "    y_preds = np.array(y_preds)\n",
    "    mae = np.mean(np.abs(y_preds - y_test))\n",
    "    return mae\n",
    "\n",
    "dense_tflite_mae = evaluate_tflite_model('Models/dense_model_quant.tflite', X_test, y_test)\n",
    "cnn_tflite_mae = evaluate_tflite_model('Models/cnn_model_quant.tflite', X_test, y_test)\n",
    "\n",
    "print(f\"Dense TFLite Model - Test MAE: {dense_tflite_mae:.3f}\")\n",
    "print(f\"CNN TFLite Model   - Test MAE: {cnn_tflite_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513e526",
   "metadata": {},
   "source": [
    "### Model Comparison Table\n",
    "\n",
    "Below is a summary of model sizes and test MAE for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Dense Original', 'Dense TFLite', 'CNN Original', 'CNN TFLite'],\n",
    "    'Size (KB)': [sizes['Dense Original'], sizes['Dense TFLite'], sizes['CNN Original'], sizes['CNN TFLite']],\n",
    "    'Test MAE': [dense_eval[1], dense_tflite_mae, cnn_eval[1], cnn_tflite_mae]\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4692a4e",
   "metadata": {},
   "source": [
    "## 7. Visualization\n",
    "\n",
    "We visualize the performance and size of the models using bar plots and error distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Model Size Comparison\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(results['Model'], results['Size (KB)'], color=['#4e79a7','#f28e2b','#76b7b2','#e15759'])\n",
    "plt.ylabel('Model Size (KB)')\n",
    "plt.title('Model Size Comparison')\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Models/model_size_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b5293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Test MAE Comparison\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(results['Model'], results['Test MAE'], color=['#4e79a7','#f28e2b','#76b7b2','#e15759'])\n",
    "plt.ylabel('Test MAE')\n",
    "plt.title('Test MAE Comparison')\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Models/model_mae_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893eafd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Error Distribution for Best Model (CNN TFLite)\n",
    "cnn_tflite_preds = []\n",
    "interpreter = tf.lite.Interpreter(model_path='Models/cnn_model_quant.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test[i:i+1].astype(np.float32)\n",
    "    scale, zero_point = input_details[0]['quantization']\n",
    "    x_q = (x / scale + zero_point).astype(np.int8)\n",
    "    interpreter.set_tensor(input_details[0]['index'], x_q)\n",
    "    interpreter.invoke()\n",
    "    y_q = interpreter.get_tensor(output_details[0]['index'])\n",
    "    y_pred = (y_q.astype(np.float32) - output_details[0]['quantization'][1]) * output_details[0]['quantization'][0]\n",
    "    cnn_tflite_preds.append(y_pred[0][0])\n",
    "cnn_tflite_preds = np.array(cnn_tflite_preds)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(cnn_tflite_preds - y_test, bins=50, color='#76b7b2', alpha=0.8)\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Error Distribution (CNN TFLite)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Models/cnn_tflite_error_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67198a08",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "- Both models achieve reasonable accuracy with very small model sizes after quantization (<60KB).\n",
    "- The quantized models are suitable for deployment on embedded systems.\n",
    "- The CNN model slightly outperforms the dense model in this task.\n",
    "- All visualizations and models are saved in the `Models/` directory."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
